{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import graphviz\n",
    "from automata_toolkit import regex_to_nfa, nfa_to_dfa, dfa_to_efficient_dfa, dfa_to_regex, visual_utils\n",
    "import copy\n",
    "import networkx as nx\n",
    "from greenery import parse\n",
    "import os\n",
    "\n",
    "\n",
    "def automata_product(A, B, alphabet):\n",
    "    # construct the product automaton of A and B through networkx (easier to work with)\n",
    "    # given the states of A and B, states of product are (s_A x s_B)\n",
    "    # transitions between s_1 and s_2 if s_1[0] -> s_2[0] in A and s_1[1] -> s_2[1] in B\n",
    "    # initial state is (s_A0, s_B0)\n",
    "    # final states are (s_Af, s_Bf) where s_Af is a final state in A and s_Bf is a final state in B\n",
    "    prod = nx.DiGraph()\n",
    "    prod.add_nodes_from([(state_A, state_B) for state_A in A['states'] for state_B in B['states']])   \n",
    "    found_start = False\n",
    "    checked_all_once = False\n",
    "    end_nodes = []\n",
    "    for u in prod.nodes():\n",
    "        for v in prod.nodes():\n",
    "            for symbol in alphabet:\n",
    "                if symbol in A['transition_function'][u[0]] and A['transition_function'][u[0]][symbol] == v[0] and symbol in B['transition_function'][u[1]] and B['transition_function'][u[1]][symbol] == v[1]:\n",
    "                    prod.add_edge(u, v, label=symbol)\n",
    "            if not found_start and u[0] == A['initial_state'] and u[1] == B['initial_state']:\n",
    "                start_node = u\n",
    "                found_start = True\n",
    "            if not checked_all_once and v[0] in A['final_states'] and v[1] in B['final_states']:\n",
    "                end_nodes.append(v)\n",
    "        checked_all_once = True\n",
    "    return prod, start_node, end_nodes\n",
    "\n",
    "def is_nonempty(A, start_node, end_nodes):\n",
    "    #check if automaton A (represented as a networkX directed graph) is non-empty\n",
    "    #equates to see if there is a path from the initial state to a final state\n",
    "    for end_node in end_nodes:\n",
    "        if nx.has_path(A, start_node, end_node):\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def step_one(original_regexp):\n",
    "    # convert original regular expression to NFA\n",
    "    nfa = regex_to_nfa.regex_to_nfa(original_regexp)\n",
    "    # convert NFA to DFA\n",
    "    dfa = nfa_to_dfa.nfa_to_dfa(nfa)\n",
    "    # convert DFA to efficient DFA A\n",
    "    return dfa_to_efficient_dfa.dfa_to_efficient_dfa(dfa)\n",
    "\n",
    "def step_two(A, new_regexps):\n",
    "    # construct A' from A\n",
    "    A_prime = copy.deepcopy(A)\n",
    "    # final states in A' are the states in A that are not final\n",
    "    A_prime['final_states'] = [state for state in A_prime['states'] if state not in A['final_states']] \n",
    "    A_prime['final_reachable_states'] = [state for state in A_prime['final_states'] if state in A_prime['reachable_states']]\n",
    "    # change the alphabet of A' to be e0, ..., ek\n",
    "    symbol_to_regex = {f'e{i+1}':regexp for i, regexp in enumerate(new_regexps)}\n",
    "    A_prime['alphabets'] = list(symbol_to_regex.keys())\n",
    "    # empty the transition function of A'\n",
    "    A_prime['transition_function'] = {state: {} for state in A_prime['states']}\n",
    "    # change the transitions of A'\n",
    "    A_temp = copy.deepcopy(A)\n",
    "    for state_i, transitions in A['transition_function'].items():\n",
    "        # for each pair of states, construct a new automaton equal to A but with initial state state_i and final state state_j\n",
    "        A_temp['initial_state'] = state_i\n",
    "        for state_j in A['states']:\n",
    "            A_temp['final_states'] = [state_j]\n",
    "            A_temp['final_reachable_states'] = [state_j if state_j in A_temp['reachable_states'] else []]\n",
    "            # for each regexp, construct an automaton and check if the product between it and A_temp is empty\n",
    "            for symbol in A_prime['alphabets']:\n",
    "                A_regexp = step_one(symbol_to_regex[symbol])\n",
    "                #check for non-emptiness of the product between A_temp and A_regexp\n",
    "                alphabet =  list(set(A_temp['alphabets']) & set( A_regexp['alphabets']))\n",
    "                A_product, start_node, end_nodes = automata_product(A_temp, A_regexp, alphabet)\n",
    "                # if non-empty, add a transition from state_i to state_j with label e_i\n",
    "                if is_nonempty(A_product, start_node, end_nodes):\n",
    "                    A_prime['transition_function'][state_i][symbol] = state_j\n",
    "    return A_prime, symbol_to_regex\n",
    "\n",
    "def step_three(A_prime):\n",
    "    #returns the complement automaton of A_prime and its relative regular expression\n",
    "    # construct the complement automaton of A_prime\n",
    "    A_complement = copy.deepcopy(A_prime)\n",
    "    A_complement['final_states'] = [state for state in A_complement['states'] if state not in A_prime['final_states']]\n",
    "    A_complement['final_reachable_states'] = [state for state in A_complement['final_states'] if state in A_complement['reachable_states']]\n",
    "    return A_complement  \n",
    "\n",
    "def translate_automata_to_regex(A, symbol_to_regex):\n",
    "    #given an automaton A and a dictionary symbol_to_regex, returns the regular expression of A\n",
    "    #substitute the symbols of any transitions with their relative regexps\n",
    "    previous_transition_function = copy.deepcopy(A['transition_function'])\n",
    "    A['alphabets'] = list(symbol_to_regex.values())\n",
    "    A['transition_function'] = {state: {} for state in A['states']}\n",
    "    for state, transitions in previous_transition_function.items():\n",
    "        for symbol, next_state in transitions.items():\n",
    "            A['transition_function'][state][symbol_to_regex[symbol]] = next_state\n",
    "    # construct the regular expression of A\n",
    "    A_regex = dfa_to_regex.dfa_to_regex(A)\n",
    "    return A_regex\n",
    "\n",
    "def generate_strings(parsed, length):\n",
    "    # generate a set of strings of length up to length from a parsed regular expression\n",
    "    strings = set()\n",
    "    for string in parsed.strings():\n",
    "        if len(string) > length:\n",
    "            break\n",
    "        strings.add(string)\n",
    "    return strings\n",
    "\n",
    "def count_coverage(a, b):\n",
    "    # count the number of strings in a that are also in b\n",
    "    return len(a & b)/len(a)\n",
    "\n",
    "def count_verbosity(a, b):\n",
    "    # count the number of strings in b that are not in a\n",
    "    return len(b - a)/len(b)\n",
    "\n",
    "def check_language_coverage(orig_regexp, new_regexp, length=20):\n",
    "    # check how far the language covered by the new regexp is from the original one, up to a certain string length\n",
    "    # convert the + sign to the | sign\n",
    "    orig_regexp = orig_regexp.replace('+', '|')\n",
    "    new_regexp = new_regexp.replace('+', '|')\n",
    "    orig_parsed = parse(orig_regexp)\n",
    "    new_parsed = parse(new_regexp)\n",
    "    orig_lang = generate_strings(orig_parsed, length)\n",
    "    new_lang = generate_strings(new_parsed, length)\n",
    "    return count_coverage(orig_lang, new_lang), count_verbosity(orig_lang, new_lang)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_regexp, new_regexps = \"a(ba+c)*\",[\"a\",\"ac*b\",\"c\"]\n",
    "A = step_one(original_regexp)\n",
    "visual_utils.draw_dfa(A, \"A_d\")\n",
    "#construct A' from A\n",
    "A_prime, symbol_to_regex = step_two(A, new_regexps)\n",
    "visual_utils.draw_dfa(A_prime, \"A'\")\n",
    "A_complement = step_three(A_prime)\n",
    "visual_utils.draw_dfa(A_complement, \"Complement of A'\")\n",
    "A_complement_regexp = translate_automata_to_regex(A_complement, symbol_to_regex)\n",
    "print(f'Original regular expression: {original_regexp}')\n",
    "print(f'Regular expressions to be replaced: {new_regexps}')\n",
    "print(f'New regular expression: {A_complement_regexp}')\n",
    "coverage, verbosity = check_language_coverage(original_regexp, A_complement_regexp, length=5)\n",
    "print(f'Coverage of the new regular expression wrt. the old one: {coverage}')\n",
    "print(f'Verbosity of the new regular expression wrt. the old one: {verbosity}')\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
